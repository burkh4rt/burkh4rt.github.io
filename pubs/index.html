<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="generator" content="Gatsby 5.13.3"/><meta name="theme-color" content="#85b09a"/><meta charset="utf-8" data-gatsby-head="true"/><meta name="viewport" content="width=device-width, initial-scale=1" data-gatsby-head="true"/><meta name="author" content="Michael C. Burkhart" data-gatsby-head="true"/><style>.gatsby-image-wrapper{position:relative;overflow:hidden}.gatsby-image-wrapper picture.object-fit-polyfill{position:static!important}.gatsby-image-wrapper img{bottom:0;height:100%;left:0;margin:0;max-width:none;padding:0;position:absolute;right:0;top:0;width:100%;object-fit:cover}.gatsby-image-wrapper [data-main-image]{opacity:0;transform:translateZ(0);transition:opacity .25s linear;will-change:opacity}.gatsby-image-wrapper-constrained{display:inline-block;vertical-align:top}</style><noscript><style>.gatsby-image-wrapper noscript [data-main-image]{opacity:1!important}.gatsby-image-wrapper [data-placeholder-image]{opacity:0!important}</style></noscript><script type="module">const e="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;e&&document.body.addEventListener("load",(function(e){const t=e.target;if(void 0===t.dataset.mainImage)return;if(void 0===t.dataset.gatsbyImageSsr)return;let a=null,n=t;for(;null===a&&n;)void 0!==n.parentNode.dataset.gatsbyImageWrapper&&(a=n.parentNode),n=n.parentNode;const o=a.querySelector("[data-placeholder-image]"),r=new Image;r.src=t.currentSrc,r.decode().catch((()=>{})).then((()=>{t.style.opacity=1,o&&(o.style.opacity=0,o.style.transition="opacity 500ms linear")}))}),!0);</script><style data-styled="" data-styled-version="6.1.8">*{box-sizing:border-box;}/*!sc*/
body{margin:0;}/*!sc*/
table{border-collapse:collapse;}/*!sc*/
input{color-scheme:light;}/*!sc*/
[role="button"]:focus:not(:focus-visible):not(.focus-visible),[role="tabpanel"][tabindex="0"]:focus:not(:focus-visible):not(.focus-visible),button:focus:not(:focus-visible):not(.focus-visible),summary:focus:not(:focus-visible):not(.focus-visible),a:focus:not(:focus-visible):not(.focus-visible){outline:none;box-shadow:none;}/*!sc*/
[tabindex="0"]:focus:not(:focus-visible):not(.focus-visible),details-dialog:focus:not(:focus-visible):not(.focus-visible){outline:none;}/*!sc*/
data-styled.g1[id="sc-global-cKLTOS1"]{content:"sc-global-cKLTOS1,"}/*!sc*/
.kyOUmg{font-family:Gill Sans Nova,Gill Sans,Helvetica,Arial,sans-serif;line-height:1.5;color:var(--fgColor-default, var(--color-fg-default, #1F2328));}/*!sc*/
data-styled.g2[id="BaseStyles__Base-sc-nfjs56-0"]{content:"kyOUmg,"}/*!sc*/
.kcbWkX{padding:0;background-color:var(--bgColor-default, var(--color-canvas-default, #ffffff));min-height:100vh;}/*!sc*/
.dGxkSL{max-width:100%;margin-left:auto;margin-right:auto;display:flex;flex-wrap:wrap;}/*!sc*/
.jTEOnj{width:100%;margin-bottom:0;}/*!sc*/
.jhWyyR{padding:16px;}/*!sc*/
@media screen and (min-width: 1012px){.jhWyyR{padding:24px;}}/*!sc*/
.huDlQP{margin-top:0;margin-bottom:0;padding-left:0;}/*!sc*/
.fEmdMo{margin-left:0;margin-right:0;display:block;height:1px;background-color:var(--borderColor-default, var(--color-border-default, #d0d7de));margin-top:0;}/*!sc*/
@media screen and (min-width: 768px){.fEmdMo{margin-left:0!important;margin-right:0!important;}}/*!sc*/
.gEUFeS{display:flex;flex:1 1 100%;flex-wrap:wrap;max-width:100%;}/*!sc*/
.ldblHz{display:flex;flex-direction:column;order:2;flex-basis:0;flex-grow:1;flex-shrink:1;min-width:1px;}/*!sc*/
.ldblHz ul{list-style:none;margin-left:0;}/*!sc*/
.ldblHz li{padding-left:1em;text-indent:-1em;padding-bottom:0.75em;max-width:calc(max(75%,500px));}/*!sc*/
.crqwoy{width:100%;max-width:1012px;margin-left:auto;margin-right:auto;flex-grow:1;padding:16px;}/*!sc*/
@media screen and (min-width: 1012px){.crqwoy{padding:24px;}}/*!sc*/
.HItXa{height:10px;}/*!sc*/
.gOGwys{order:4;width:100%;margin-top:0;}/*!sc*/
.cVYIfo{margin-left:0;margin-right:0;display:block;height:1px;background-color:var(--borderColor-default, var(--color-border-default, #d0d7de));margin-bottom:0;}/*!sc*/
@media screen and (min-width: 768px){.cVYIfo{margin-left:0!important;margin-right:0!important;}}/*!sc*/
.bPkcLO{padding:16px;}/*!sc*/
data-styled.g3[id="Box-sc-g0xbh4-0"]{content:"kcbWkX,dGxkSL,jTEOnj,jhWyyR,huDlQP,fEmdMo,gEUFeS,ldblHz,crqwoy,HItXa,gOGwys,cVYIfo,bPkcLO,"}/*!sc*/
.kvHHJt{display:inline-block;white-space:nowrap;list-style:none;}/*!sc*/
.kvHHJt::after{font-size:14px;content:'';display:inline-block;height:0.8em;margin:0 0.5em;border-right:0.1em solid;border-color:var(--fgColor-muted, var(--color-fg-muted, #656d76));transform:rotate(15deg) translateY(0.0625em);}/*!sc*/
.kvHHJt:first-child{margin-left:0;}/*!sc*/
.kvHHJt:last-child::after{content:none;}/*!sc*/
data-styled.g5[id="Breadcrumbs__Wrapper-sc-9m4wsf-0"]{content:"kvHHJt,"}/*!sc*/
.hEWrLC{display:flex;justify-content:space-between;}/*!sc*/
data-styled.g6[id="Breadcrumbs__BreadcrumbsBase-sc-9m4wsf-1"]{content:"hEWrLC,"}/*!sc*/
.vLHOa{color:var(--fgColor-accent, var(--color-accent-fg, #0969da));display:inline-block;font-size:14px;text-decoration:none;}/*!sc*/
.vLHOa:hover,.vLHOa:focus{text-decoration:underline;}/*!sc*/
.vLHOa.selected{color:var(--fgColor-default, var(--color-fg-default, #1F2328));pointer-events:none;}/*!sc*/
.vLHOa.selected:focus{text-decoration:none;}/*!sc*/
data-styled.g7[id="Breadcrumbs__BreadcrumbsItem-sc-9m4wsf-2"]{content:"vLHOa,"}/*!sc*/
.fhaUbU{position:relative;padding-top:24px;padding-bottom:24px;margin-bottom:24px;border-bottom:1px solid var(--borderColor-default, var(--color-border-default, #d0d7de));font-weight:lighter;}/*!sc*/
data-styled.g8[id="Pagehead-sc-diawfz-0"]{content:"fhaUbU,"}/*!sc*/
.gXkolb{color:var(--fgColor-accent, var(--color-accent-fg, #0969da));text-decoration:none;}/*!sc*/
[data-a11y-link-underlines='true'] .gXkolb[data-inline='true']{text-decoration:underline;}/*!sc*/
.gXkolb:hover{text-decoration:underline;}/*!sc*/
.gXkolb:is(button){display:inline-block;padding:0;font-size:inherit;white-space:nowrap;cursor:pointer;user-select:none;background-color:transparent;border:0;appearance:none;}/*!sc*/
data-styled.g10[id="Link__StyledLink-sc-14289xe-0"]{content:"gXkolb,"}/*!sc*/
.iPljmh{display:flex;justify-content:space-between;}/*!sc*/
.iPljmh .SubNav-body{display:flex;margin-bottom:-1px;}/*!sc*/
.iPljmh .SubNav-body >*{margin-left:8px;}/*!sc*/
.iPljmh .SubNav-body >*:first-child{margin-left:0;}/*!sc*/
.iPljmh .SubNav-actions{align-self:center;}/*!sc*/
data-styled.g11[id="SubNav__SubNavBase-sc-1t692wx-0"]{content:"iPljmh,"}/*!sc*/
.QvgB{display:flex;}/*!sc*/
data-styled.g12[id="SubNav__SubNavLinks-sc-1t692wx-1"]{content:"QvgB,"}/*!sc*/
.hhVQkq{padding-left:16px;padding-right:16px;font-weight:500;font-size:14px;line-height:20px;min-height:34px;color:var(--fgColor-default, var(--color-fg-default, #1F2328));text-align:center;text-decoration:none;border-top:1px solid var(--borderColor-default, var(--color-border-default, #d0d7de));border-bottom:1px solid var(--borderColor-default, var(--color-border-default, #d0d7de));border-right:1px solid var(--borderColor-default, var(--color-border-default, #d0d7de));display:flex;align-items:center;}/*!sc*/
.hhVQkq:first-of-type{border-top-left-radius:6px;border-bottom-left-radius:6px;border-left:1px solid var(--borderColor-default, var(--color-border-default, #d0d7de));}/*!sc*/
.hhVQkq:last-of-type{border-top-right-radius:6px;border-bottom-right-radius:6px;}/*!sc*/
.hhVQkq:hover,.hhVQkq:focus{text-decoration:none;background-color:var(--bgColor-muted, var(--color-canvas-subtle, #f6f8fa));transition:background-color 0.2s ease;}/*!sc*/
.hhVQkq:hover .SubNav-octicon,.hhVQkq:focus .SubNav-octicon{color:var(--fgColor-muted, var(--color-fg-muted, #656d76));}/*!sc*/
.hhVQkq.selected{color:var(--fgColor-onEmphasis, var(--color-fg-on-emphasis, #ffffff));background-color:var(--bgColor-accent-emphasis, var(--color-accent-emphasis, #0969da));border-color:var(--bgColor-accent-emphasis, var(--color-accent-emphasis, #0969da));}/*!sc*/
.hhVQkq.selected .SubNav-octicon{color:var(--fgColor-onEmphasis, var(--color-fg-on-emphasis, #ffffff));}/*!sc*/
data-styled.g13[id="SubNav__SubNavLink-sc-1t692wx-2"]{content:"hhVQkq,"}/*!sc*/
@font-face{font-family:"Gill Sans Nova";src:url(/static/GillSansNova-Book-b1318c5cc0f0a333dbd883526362b04e.woff2) format("woff2"),url(/static/GillSansNova-Book-b1318c5cc0f0a333dbd883526362b04e.woff) format("woff"),url(/static/GillSansNova-Book-3965f832825376a434e7fb2418411b86.otf) format("opentype"),url("https://use.typekit.net/af/078c93/00000000000000003b9b1f81/27/l") format("woff2"),url("https://use.typekit.net/af/078c93/00000000000000003b9b1f81/27/d") format("woff");font-style:normal;font-weight:400;font-feature-settings:"kern" 1,"onum" 1;font-display:block;}/*!sc*/
@font-face{font-family:"Gill Sans Nova";src:url(/static/GillSansNova-BookItalic-4a78ec1048c44636323ef2437c4ea759.woff2) format("woff2"),url(/static/GillSansNova-BookItalic-4a78ec1048c44636323ef2437c4ea759.woff) format("woff"),url(/static/GillSansNova-BookItalic-f78972b5e9405cb4f9db125d79529f12.otf) format("opentype"),url("https://use.typekit.net/af/7c22c1/00000000000000003b9b1f82/27/l") format("woff2"),url("https://use.typekit.net/af/7c22c1/00000000000000003b9b1f82/27/d") format("woff");font-style:italic;font-weight:400;font-feature-settings:"kern" 1,"onum" 1;font-display:block;}/*!sc*/
data-styled.g14[id="sc-global-fzdFZq1"]{content:"sc-global-fzdFZq1,"}/*!sc*/
</style><link rel="preconnect" href="https://www.googletagmanager.com"/><link rel="dns-prefetch" href="https://www.googletagmanager.com"/><link rel="icon" href="/favicon-32x32.png?v=b2d0448ccb787fcc3efe66597995e612" type="image/png"/><link rel="icon" href="/favicon.svg?v=b2d0448ccb787fcc3efe66597995e612" type="image/svg+xml"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=b2d0448ccb787fcc3efe66597995e612"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=b2d0448ccb787fcc3efe66597995e612"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=b2d0448ccb787fcc3efe66597995e612"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=b2d0448ccb787fcc3efe66597995e612"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=b2d0448ccb787fcc3efe66597995e612"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=b2d0448ccb787fcc3efe66597995e612"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=b2d0448ccb787fcc3efe66597995e612"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=b2d0448ccb787fcc3efe66597995e612"/><link rel="canonical" href="https://burkh4rt.github.io/pubs/" data-baseprotocol="https:" data-basehost="burkh4rt.github.io"/><title data-gatsby-head="true">publications</title><link rel="canonical" href="https://burkh4rt.github.io/pubs/" data-gatsby-head="true"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div color="fg.default" font-family="normal" lineHeight="default" data-portal-root="true" data-color-mode="light" data-light-theme="light" data-dark-theme="dark_dimmed" class="BaseStyles__Base-sc-nfjs56-0 kyOUmg"><div style="--sticky-pane-height:100vh" sx="[object Object]" class="Box-sc-g0xbh4-0 kcbWkX"><div sx="[object Object]" class="Box-sc-g0xbh4-0 dGxkSL"><header sx="[object Object]" class="Box-sc-g0xbh4-0 jTEOnj"><div sx="[object Object]" class="Box-sc-g0xbh4-0 jhWyyR"><nav aria-label="Breadcrumbs" class="Breadcrumbs__BreadcrumbsBase-sc-9m4wsf-1 hEWrLC"><ol my="0" pl="0" class="Box-sc-g0xbh4-0 huDlQP"><li class="Breadcrumbs__Wrapper-sc-9m4wsf-0 kvHHJt"><a href="/" class="Breadcrumbs__BreadcrumbsItem-sc-9m4wsf-2 vLHOa">home</a></li><li class="Breadcrumbs__Wrapper-sc-9m4wsf-0 kvHHJt"><a href="#" selected="" class="Breadcrumbs__BreadcrumbsItem-sc-9m4wsf-2 vLHOa selected" aria-current="page">publications</a></li></ol></nav></div><div class="Box-sc-g0xbh4-0 fEmdMo"></div></header><div sx="[object Object]" class="Box-sc-g0xbh4-0 gEUFeS"><main sx="[object Object]" class="Box-sc-g0xbh4-0 ldblHz"><div class="Box-sc-g0xbh4-0"></div><div sx="[object Object]" class="Box-sc-g0xbh4-0 crqwoy"><h3 id="papers" sx="[object Object]" class="Pagehead-sc-diawfz-0 fhaUbU">Papers</h3><span class="Text-sc-17v1xeu-0 dtKlfb"><ul><li>M. Burkhart &amp; G. Ruiz.<!-- --> <a data-inline="true" href="https://doi.org/10.1016/j.jocs.2023.102054" target="_blank" rel="noopener noreferrer" class="Link__StyledLink-sc-14289xe-0 gXkolb">Neuroevolutionary representations for learning heterogeneous treatment effects.</a> <!-- -->Journal of Computational Science 71 (2023) <a data-inline="true" href="/pubs/Burkhart-Ruiz-2023-J-Comput-Sci.pdf" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">pdf <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a></li><li>M. Burkhart.<!-- --> <a data-inline="true" href="https://doi.org/10.1007/s11590-022-01895-5" target="_blank" rel="noopener noreferrer" class="Link__StyledLink-sc-14289xe-0 gXkolb">Discriminative Bayesian filtering lends momentum to the stochastic Newton method for minimizing log-convex functions.</a> <!-- -->Optimization Letters 17 (2023) <a data-inline="true" href="https://mathscinet.ams.org/mathscinet-getitem?mr=4557438" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">MR4557438 <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a> <a data-inline="true" href="/pubs/Burkhart-2023-Optim-Lett.pdf" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">pdf <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a></li><li>M. Burkhart.<!-- --> <a data-inline="true" href="https://doi.org/10.1017/S0013091522000499" target="_blank" rel="noopener noreferrer" class="Link__StyledLink-sc-14289xe-0 gXkolb">Conjugacy conditions for supersoluble complements of an abelian base and a fixed point result for non-coprime actions.</a> <!-- -->Proceedings of the Edinburgh Mathematical Society 65 (2022) <a data-inline="true" href="https://mathscinet.ams.org/mathscinet-getitem?mr=4542651" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">MR4542651 <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a> <a data-inline="true" href="/pubs/Burkhart-2022-Proc-Edinb-Math-Soc.pdf" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">pdf <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a></li><li>M. Burkhart &amp; G. Ruiz.<!-- --> <a data-inline="true" href="https://doi.org/10.1007/978-3-031-08754-7_1" target="_blank" rel="noopener noreferrer" class="Link__StyledLink-sc-14289xe-0 gXkolb">Neuroevolutionary feature representations for causal inference.</a> <!-- -->Computational Science – ICCS 2022 <a data-inline="true" href="/pubs/Burkhart-Ruiz-2022-Comput-Sci.pdf" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">pdf <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a></li><li>M. Burkhart.<!-- --> <a data-inline="true" href="https://doi.org/10.1007/978-3-030-77964-1_22" target="_blank" rel="noopener noreferrer" class="Link__StyledLink-sc-14289xe-0 gXkolb">Discriminative Bayesian filtering for the semi-supervised augmentation of sequential observation data.</a> <!-- -->Computational Science – ICCS 2021 <a data-inline="true" href="https://mathscinet.ams.org/mathscinet-getitem?mr=4371656" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">MR4371656 <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a> <a data-inline="true" href="/pubs/Burkhart-2021-Comput-Sci.pdf" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">pdf <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a></li><li>M. Burkhart &amp; K. Shan.<!-- --> <a data-inline="true" href="https://doi.org/10.1007/978-3-030-50420-5_22" target="_blank" rel="noopener noreferrer" class="Link__StyledLink-sc-14289xe-0 gXkolb">Deep low-density separation for semi-supervised classification.</a> <!-- -->Computational Science – ICCS 2020 <a data-inline="true" href="https://mathscinet.ams.org/mathscinet-getitem?mr=4152505" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">MR4152505 <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a> <a data-inline="true" href="/pubs/Burkhart-Shan-2020-Comput-Sci.pdf" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">pdf <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a></li><li>M. Burkhart, D. Brandman, B. Franco, L. Hochberg, &amp; M. Harrison.<!-- --> <a data-inline="true" href="https://doi.org/10.1162/neco_a_01275" target="_blank" rel="noopener noreferrer" class="Link__StyledLink-sc-14289xe-0 gXkolb">The discriminative Kalman filter for Bayesian filtering with nonlinear and nongaussian observation models.</a> <!-- -->Neural Computation 32 (2020) <a data-inline="true" href="https://mathscinet.ams.org/mathscinet-getitem?mr=4101168" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">MR4101168 <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a> <a data-inline="true" href="/pubs/Burkhart-et-al-2020-Neural-Comput.pdf" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">pdf <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a></li><li>M. Burkhart &amp; K. Modarresi.<!-- --> <a data-inline="true" href="https://doi.org/10.1007/978-3-030-22741-8_42" target="_blank" rel="noopener noreferrer" class="Link__StyledLink-sc-14289xe-0 gXkolb">Determining adaptive loss functions and algorithms for predictive models.</a> <!-- -->Computational Science – ICCS 2019 <a data-inline="true" href="/pubs/Burkhart-Modarresi-2019-Comput-Sci-2.pdf" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">pdf <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a></li><li>M. Burkhart &amp; K. Modarresi.<!-- --> <a data-inline="true" href="https://doi.org/10.1007/978-3-030-22741-8_43" target="_blank" rel="noopener noreferrer" class="Link__StyledLink-sc-14289xe-0 gXkolb">Adaptive objective functions and distance metrics for recommendation systems.</a> <!-- -->Computational Science – ICCS 2019 <a data-inline="true" href="https://mathscinet.ams.org/mathscinet-getitem?mr=3975427" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">MR3975427 <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a> <a data-inline="true" href="/pubs/Burkhart-Modarresi-2019-Comput-Sci.pdf" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">pdf <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a></li><li>D. Brandman, M. Burkhart, J. Kelemen, B. Franco, M. Harrison, &amp; L. Hochberg.<!-- --> <a data-inline="true" href="https://doi.org/10.1162/neco_a_01129" target="_blank" rel="noopener noreferrer" class="Link__StyledLink-sc-14289xe-0 gXkolb">Robust closed-loop control of a cursor in a person with tetraplegia using Gaussian process regression.</a> <!-- -->Neural Computation 30 (2018) <a data-inline="true" href="https://mathscinet.ams.org/mathscinet-getitem?mr=3873814" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">MR3873814 <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a> <a data-inline="true" href="/pubs/Brandman-et-al-2018-Neural-Comput.pdf" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">pdf <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a></li><li>D. Brandman, T. Hosman, J. Saab, M. Burkhart, B. Shanahan, J. Ciancibello, …, M. Harrison, J. Simeral, &amp; L. Hochberg.<!-- --> <a data-inline="true" href="https://doi.org/10.1088/1741-2552/aa9ee7" target="_blank" rel="noopener noreferrer" class="Link__StyledLink-sc-14289xe-0 gXkolb">Rapid calibration of an intracortical brain computer interface for people with tetraplegia.</a> <!-- -->Journal of Neural Engineering 15 (2018) <a data-inline="true" href="/pubs/Brandman-et-al-2018-J-Neural-Eng.pdf" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">pdf <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a></li><li>M. Burkhart, Y. Heo, &amp; V. Zavala.<!-- --> <a data-inline="true" href="https://doi.org/10.1016/j.enbuild.2014.01.048" target="_blank" rel="noopener noreferrer" class="Link__StyledLink-sc-14289xe-0 gXkolb">Measurement and verification of building systems under uncertain data: A Gaussian process modeling approach.</a> <!-- -->Energy and Buildings 75 (2014) <a data-inline="true" href="/pubs/Burkhart-et-al-2014-Energy-Build.pdf" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">pdf <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a></li></ul></span><h3 id="preprints" sx="[object Object]" class="Pagehead-sc-diawfz-0 fhaUbU">Preprints</h3><span class="Text-sc-17v1xeu-0 dtKlfb"><ul><li>M. Burkhart.<!-- --> <a data-inline="true" href="https://doi.org/10.1017/prm.2023.96" target="_blank" rel="noopener noreferrer" class="Link__StyledLink-sc-14289xe-0 gXkolb">Fixed point conditions for non-coprime actions.</a> <!-- -->Proceedings of the Royal Society of Edinburgh Section A: Mathematics (to appear) <a data-inline="true" href="/pubs/Burkhart-2023-Proc-Roy-Soc-Edinb-Sect-A-Math.pdf" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">pdf <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a></li><li>M. Abroshan, M. Burkhart, O. Giles, S. Greenbury, Z. Kourtzi, J. Roberts, M. van der Schaar, J. Steyn, A. Wilson, &amp; M. Yong.<!-- --> <a data-inline="true" href="https://doi.org/10.48550/arXiv.2303.01513" target="_blank" rel="noopener noreferrer" class="Link__StyledLink-sc-14289xe-0 gXkolb">Safe AI for health and beyond – monitoring to transform a health service.</a> <!-- -->arXiv:2303.01513 <a data-inline="true" href="/pubs/Abroshan-et-al-2023-arXiv.pdf" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">pdf <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a></li><li>R. Li, E. Harshfield, S. Bell, M. Burkhart, A. Tuladhar, S. Hilal, D. Tozer, F. Chappell, S. Makin, J. Lo, J. Wardlaw, F.-E. de Leeuw, C. Chen, Z. Kourtzi, &amp; H. Markus.<!-- --> <a data-inline="true" href="https://doi.org/10.1016/j.cccb.2023.100179" target="_blank" rel="noopener noreferrer" class="Link__StyledLink-sc-14289xe-0 gXkolb">Predicting incident dementia in cerebral small vessel disease: comparison of machine learning and traditional statistical models.</a> <!-- -->Cerebral Circulation – Cognition and Behavior <a data-inline="true" href="/pubs/Li-et-al-2023-Cereb-Circ-Cogn-Behav.pdf" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">pdf <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a></li><li>R. Borchert, T. Azevedo, A. Badhwar, J. Bernal, M. Betts, R. Bruffaerts, M. Burkhart, I. Dewachter, …, D. Llewellyn, M. Veldsman, &amp; T. Rittman.<!-- --> <a data-inline="true" href="https://doi.org/10.1002/alz.13412" target="_blank" rel="noopener noreferrer" class="Link__StyledLink-sc-14289xe-0 gXkolb">Artificial intelligence for diagnostic and prognostic neuroimaging in dementia: a systematic review.</a> <!-- -->Alzheimer&#x27;s &amp; Dementia <a data-inline="true" href="/pubs/Borchert-et-al-2023-Alzheimers-Dement.pdf" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">pdf <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a></li></ul></span><h3 id="dissertation" sx="[object Object]" class="Pagehead-sc-diawfz-0 fhaUbU">Dissertation</h3><span class="Text-sc-17v1xeu-0 dtKlfb"><ul><li>M. Burkhart.<!-- --> <a data-inline="true" href="https://doi.org/10.26300/nhfp-xv22" target="_blank" rel="noopener noreferrer" class="Link__StyledLink-sc-14289xe-0 gXkolb">“A Discriminative Approach to Bayesian Filtering with Applications to Human Neural Decoding.”</a> <!-- -->Ph.D. Dissertation, Brown University, Division of Applied Mathematics (2019) <a data-inline="true" href="https://mathscinet.ams.org/mathscinet-getitem?mr=4158190" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">MR4158190 <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a> <a data-inline="true" href="/pubs/Burkhart-2019.pdf" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">pdf <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a></li></ul><h3 id="patents" sx="[object Object]" class="Pagehead-sc-diawfz-0 fhaUbU">Patents &amp; Pending</h3><ul><li>M. Burkhart &amp; G. Ruiz.<!-- --> <a data-inline="true" href="https://patents.google.com/patent/US20230376776A1" target="_blank" rel="noopener noreferrer" class="Link__StyledLink-sc-14289xe-0 gXkolb">Causal inference via neuroevolutionary selection.</a> <!-- -->U.S. Patent Application #17/748,891. Filed 2022. Published as US 2023/0376776 A1 <a data-inline="true" href="/pubs/Burkhart-Ruiz-US20230376776A1.pdf" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">pdf <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a></li><li>M. Burkhart &amp; K. Shan.<!-- --> <a data-inline="true" href="https://patents.google.com/patent/US11455518B2" target="_blank" rel="noopener noreferrer" class="Link__StyledLink-sc-14289xe-0 gXkolb">User classification from data via deep segmentation for semi-supervised learning.</a> <!-- -->U.S. Patent Application #16/681,239. Filed 2019. Published as US 2021/0142152 A1 <a data-inline="true" href="/pubs/Burkhart-Shan-US20210142152A1.pdf" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">pdf <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a>  Granted 2022 as US 11,455,518 B2 <a data-inline="true" href="/pubs/Burkhart-Shan-US11455518B2.pdf" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">pdf <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a></li><li>M. Burkhart &amp; K. Modarresi.<!-- --> <a data-inline="true" href="https://patents.google.com/patent/US11816562B2" target="_blank" rel="noopener noreferrer" class="Link__StyledLink-sc-14289xe-0 gXkolb">Digital experience enhancement using an ensemble deep learning model.</a> <!-- -->U.S. Patent Application #16/375,627. Filed 2019. Published as US 2020/0320382 A1 <a data-inline="true" href="/pubs/Burkhart-Modarresi-US20200320382A1.pdf" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">pdf <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a>  Granted 2023 as US 11,816,562 B2 <a data-inline="true" href="/pubs/Burkhart-Modarresi-US11816562B2.pdf" target="_blank" rel="noopener noreferrer" style="white-space:nowrap" class="Link__StyledLink-sc-14289xe-0 gXkolb">pdf <svg aria-hidden="true" focusable="false" class="octicon octicon-link-external" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="M3.75 2h3.5a.75.75 0 0 1 0 1.5h-3.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-3.5a.75.75 0 0 1 1.5 0v3.5A1.75 1.75 0 0 1 12.25 14h-8.5A1.75 1.75 0 0 1 2 12.25v-8.5C2 2.784 2.784 2 3.75 2Zm6.854-1h4.146a.25.25 0 0 1 .25.25v4.146a.25.25 0 0 1-.427.177L13.03 4.03 9.28 7.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.75-3.75-1.543-1.543A.25.25 0 0 1 10.604 1Z"></path></svg></a></li></ul></span><div height="10" class="Box-sc-g0xbh4-0 HItXa"></div><nav class="SubNav__SubNavBase-sc-1t692wx-0 iPljmh SubNav" aria-label="Main" style="flex-direction:row;justify-content:flex-end"><div class="SubNav-body"><div class="SubNav__SubNavLinks-sc-1t692wx-1 QvgB"><a href="/" rel="noopener noreferrer" class="SubNav__SubNavLink-sc-1t692wx-2 hhVQkq SubNav-item">home</a></div></div></nav><div height="10" class="Box-sc-g0xbh4-0 HItXa"></div></div><div class="Box-sc-g0xbh4-0"></div></main><footer sx="[object Object]" class="Box-sc-g0xbh4-0 gOGwys"><div class="Box-sc-g0xbh4-0 cVYIfo"></div><div sx="[object Object]" class="Box-sc-g0xbh4-0 bPkcLO"><p align="end" style="padding:0;margin:0;text-align:right" class="Text-sc-17v1xeu-0 dtKlfb"><svg aria-hidden="true" focusable="false" class="Octicon-sc-9kayk9-0" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:middle;overflow:visible"><path d="m12.596 11.596-3.535 3.536a1.5 1.5 0 0 1-2.122 0l-3.535-3.536a6.5 6.5 0 1 1 9.192-9.193 6.5 6.5 0 0 1 0 9.193Zm-1.06-8.132v-.001a5 5 0 1 0-7.072 7.072L8 14.07l3.536-3.534a5 5 0 0 0 0-7.072ZM8 9a2 2 0 1 1-.001-3.999A2 2 0 0 1 8 9Z"></path></svg> Plainfield, Indiana © <!-- -->2024</p></div></footer></div></div></div></div><script type="application/json" id="__PRIMER_DATA__">{"resolvedServerColorMode":"day"}</script></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-P9BKGH7JBF"></script><script>
      
      
      if(true) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-P9BKGH7JBF', {"send_page_view":false});
      }
      </script><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/pubs/";/*]]>*/</script><!-- slice-start id="_gatsby-scripts-1" -->
          <script
            id="gatsby-chunk-mapping"
          >
            window.___chunkMapping="{\"polyfill\":[\"/polyfill-dc082e0b5f03d57787f8.js\"],\"app\":[\"/app-b6edbfee6d45397de98c.js\"],\"component---cache-caches-gatsby-plugin-offline-app-shell-js\":[\"/component---cache-caches-gatsby-plugin-offline-app-shell-js-ce339f83a2a14a1ab258.js\"],\"component---src-pages-404-jsx\":[\"/component---src-pages-404-jsx-5508894b7efaa880b71e.js\"],\"component---src-pages-index-jsx\":[\"/component---src-pages-index-jsx-ae06f52ae3cde1d2ccd8.js\"],\"component---src-pages-links-jsx\":[\"/component---src-pages-links-jsx-522920e1c2b9c45f846b.js\"],\"component---src-pages-pubs-jsx\":[\"/component---src-pages-pubs-jsx-b63edf9f1830328d4e35.js\"]}";
          </script>
        <script>window.___webpackCompilationHash="79d882c8fe0171c12b6d";</script><script src="/webpack-runtime-f9ab78bef5248e706cfe.js" nomodule></script><script src="/polyfill-dc082e0b5f03d57787f8.js" nomodule></script><script src="/webpack-runtime-f9ab78bef5248e706cfe.js" async></script><script src="/framework-7df336e8195cf8a3064d.js" async></script><script src="/app-b6edbfee6d45397de98c.js" async></script><!-- slice-end id="_gatsby-scripts-1" --></body></html>